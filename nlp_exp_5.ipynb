{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhruv21csu155/nlp/blob/main/nlp_exp_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0OAXJme6hIG7"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "0DSqhvjRFRih",
        "outputId": "887ede3c-6b7b-4956-daed-b28c4d5fa341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  words = [word.lower() for word in tokens if word.isalpha()]\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "  return words"
      ],
      "metadata": {
        "id": "-OVWjw_FGLw7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_sense_disambiguation(word):\n",
        "  synsets = wordnet.synsets(word)\n",
        "  if synsets:\n",
        "    return synsets[0]\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "oIl37IhjG67C"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_info(word):\n",
        "  sense = word_sense_disambiguation(word)\n",
        "\n",
        "  if sense:\n",
        "    synonyms = [lemma.name() for lemma in sense.lemmas()]\n",
        "    antonyms = []\n",
        "\n",
        "    for lemma in sense.lemmas():\n",
        "      antonyms.extend(lemma.antonyms())\n",
        "\n",
        "    antonyms = [antonym.name() for antonym in antonyms]\n",
        "\n",
        "    hypernyms = [hypernym.name() for hypernym in sense.hypernyms()]\n",
        "\n",
        "    hyponyms = [hyponym.name() for hyponym in sense.hyponyms()]\n",
        "\n",
        "    return {\n",
        "        'Synonyms': synonyms,\n",
        "        'Antonyms': antonyms,\n",
        "        'Hypernyms': hypernyms,\n",
        "        'Hyponyms': hyponyms\n",
        "    }\n",
        "\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "P8z70eyxHPSI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(file_path):\n",
        "  with open(file_path, 'r', encoding = 'utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "  words = preprocess(text)\n",
        "\n",
        "  word_info_dict = {}\n",
        "  for word in words:\n",
        "    if word not in word_info_dict:\n",
        "      word_info = get_word_info(word)\n",
        "      if word_info:\n",
        "        word_info_dict[word] = word_info\n",
        "\n",
        "  for word, info in word_info_dict.items():\n",
        "    print(f\"Word: {word}\")\n",
        "    print(f\"Synonyms: {','.join(info['Synonyms'])}\")\n",
        "    print(f\"Antonyms: {','.join(info['Antonyms'])}\")\n",
        "    print(f\"Hypernyms: {','.join(info['Hypernyms'])}\")\n",
        "    print(f\"Hyponyms: {','.join(info['Hyponyms'])}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "vWQmOqujHrMA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main('/content/nlp.txt')"
      ],
      "metadata": {
        "id": "cQo_Xtr6HuAf",
        "outputId": "385bed71-cadb-4075-fe88-29ee601caad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: nlp\n",
            "Synonyms: natural_language_processing,NLP,human_language_technology\n",
            "Antonyms: \n",
            "Hypernyms: information_science.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: or\n",
            "Synonyms: Oregon,Beaver_State,OR\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: natural\n",
            "Synonyms: natural\n",
            "Antonyms: \n",
            "Hypernyms: achiever.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: language\n",
            "Synonyms: language,linguistic_communication\n",
            "Antonyms: \n",
            "Hypernyms: communication.n.02\n",
            "Hyponyms: artificial_language.n.01,barrage.n.01,dead_language.n.01,indigenous_language.n.01,lingua_franca.n.01,metalanguage.n.01,native_language.n.01,natural_language.n.01,object_language.n.02,sign_language.n.01,slanguage.n.01,source_language.n.01,string_of_words.n.01,superstrate.n.02,usage.n.03,words.n.03\n",
            "\n",
            "\n",
            "Word: processing\n",
            "Synonyms: processing\n",
            "Antonyms: \n",
            "Hypernyms: process.n.06\n",
            "Hyponyms: blowing.n.01,data_processing.n.01,development.n.08,refining.n.01,vulcanization.n.01\n",
            "\n",
            "\n",
            "Word: is\n",
            "Synonyms: be\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: abound.v.01,accept.v.08,account.v.01,account_for.v.01,act.v.06,answer.v.06,appear.v.04,bake.v.04,balance.v.04,be_well.v.01,beat.v.12,begin.v.06,begin.v.07,belong.v.01,belong.v.02,belong.v.04,belong.v.05,breathe.v.04,buy.v.03,clean.v.05,cohere.v.03,come_in_for.v.01,come_in_handy.v.01,compact.v.01,compare.v.02,confuse.v.02,connect.v.07,consist.v.02,consist.v.04,contain.v.04,contain.v.05,continue.v.10,cost.v.01,count.v.02,count.v.07,cover.v.18,cut.v.25,cut_across.v.02,deck.v.01,depend.v.01,deserve.v.01,disagree.v.02,distribute.v.09,diverge.v.02,draw.v.21,end.v.03,fall.v.04,fall.v.16,feel.v.04,figure.v.02,fit.v.07,gape.v.02,go.v.10,gravitate.v.02,hail.v.02,hang.v.06,head.v.04,hold.v.17,hoodoo.v.01,hum.v.02,impend.v.01,incarnate.v.02,iridesce.v.01,jumble.v.01,kill.v.04,lend.v.03,let_go.v.02,lie.v.04,litter.v.01,loiter.v.01,look.v.02,look.v.03,lubricate.v.01,make.v.31,make_sense.v.01,measure.v.03,mope.v.02,object.v.02,osculate.v.01,owe.v.03,pay.v.07,point.v.10,press.v.08,promise.v.04,prove.v.01,put_out.v.06,rage.v.02,range.v.01,rank.v.01,rate.v.02,recognize.v.08,relate.v.04,remain.v.03,represent.v.03,rest.v.01,retard.v.02,run.v.05,run_into.v.01,rut.v.01,seem.v.03,seethe.v.02,sell.v.02,sell.v.06,sell.v.07,shine.v.04,shine.v.05,sparkle.v.02,specify.v.03,squat.v.02,stagnate.v.01,stagnate.v.03,stand.v.02,stand.v.03,stand_by.v.03,stay.v.01,stay.v.04,stick.v.04,stink.v.01,subtend.v.01,suck.v.04,suffer.v.06,suffer.v.08,suit.v.02,swim.v.03,swim.v.04,swing.v.10,tend.v.01,test.v.04,total.v.01,translate.v.07,transplant.v.02,trim.v.05,underlie.v.01,want.v.02,wash.v.05,wind.v.02,work.v.14\n",
            "\n",
            "\n",
            "Word: a\n",
            "Synonyms: angstrom,angstrom_unit,A\n",
            "Antonyms: \n",
            "Hypernyms: metric_linear_unit.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: field\n",
            "Synonyms: field\n",
            "Antonyms: \n",
            "Hypernyms: tract.n.01\n",
            "Hyponyms: campus.n.01,firebreak.n.01,grainfield.n.01,lawn.n.01,paddy.n.02,yard.n.02\n",
            "\n",
            "\n",
            "Word: at\n",
            "Synonyms: astatine,At,atomic_number_85\n",
            "Antonyms: \n",
            "Hypernyms: chemical_element.n.01,halogen.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: intersection\n",
            "Synonyms: intersection,intersection_point,point_of_intersection\n",
            "Antonyms: \n",
            "Hypernyms: point.n.01\n",
            "Hyponyms: metacenter.n.01,vertex.n.01\n",
            "\n",
            "\n",
            "Word: artificial\n",
            "Synonyms: artificial,unreal\n",
            "Antonyms: natural\n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: intelligence\n",
            "Synonyms: intelligence\n",
            "Antonyms: stupidity\n",
            "Hypernyms: ability.n.02\n",
            "Hyponyms: acuteness.n.02,brain.n.02,breadth.n.01,brightness.n.02,brilliance.n.03,mental_quickness.n.01,mind.n.07,nimbleness.n.01,nonverbal_intelligence.n.01,precociousness.n.01,shrewdness.n.01,verbal_intelligence.n.01,wits.n.01\n",
            "\n",
            "\n",
            "Word: linguistics\n",
            "Synonyms: linguistics\n",
            "Antonyms: \n",
            "Hypernyms: science.n.01\n",
            "Hyponyms: computational_linguistics.n.01,descriptive_linguistics.n.01,dialect_geography.n.01,etymology.n.02,historical_linguistics.n.01,neurolinguistics.n.01,pragmatics.n.01,prescriptive_linguistics.n.01,semantics.n.01,sociolinguistics.n.01,structuralism.n.01,synchronic_linguistics.n.01\n",
            "\n",
            "\n",
            "Word: focusing\n",
            "Synonyms: focus,focusing,focussing,focal_point,direction,centering\n",
            "Antonyms: \n",
            "Hypernyms: concentration.n.05\n",
            "Hyponyms: particularism.n.01\n",
            "\n",
            "\n",
            "Word: on\n",
            "Synonyms: on\n",
            "Antonyms: off\n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: interaction\n",
            "Synonyms: interaction\n",
            "Antonyms: \n",
            "Hypernyms: action.n.01\n",
            "Hyponyms: contact.n.01,interchange.n.02,interplay.n.01\n",
            "\n",
            "\n",
            "Word: between\n",
            "Synonyms: between,betwixt\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: computer\n",
            "Synonyms: computer,computing_machine,computing_device,data_processor,electronic_computer,information_processing_system\n",
            "Antonyms: \n",
            "Hypernyms: machine.n.01\n",
            "Hyponyms: analog_computer.n.01,digital_computer.n.01,home_computer.n.01,node.n.08,number_cruncher.n.02,pari-mutuel_machine.n.01,predictor.n.03,server.n.03,turing_machine.n.01,web_site.n.01\n",
            "\n",
            "\n",
            "Word: human\n",
            "Synonyms: homo,man,human_being,human\n",
            "Antonyms: \n",
            "Hypernyms: hominid.n.01\n",
            "Hyponyms: homo_erectus.n.01,homo_habilis.n.01,homo_sapiens.n.01,homo_soloensis.n.01,neandertal_man.n.01,rhodesian_man.n.01,world.n.08\n",
            "\n",
            "\n",
            "Word: it\n",
            "Synonyms: information_technology,IT\n",
            "Antonyms: \n",
            "Hypernyms: engineering.n.02\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: enables\n",
            "Synonyms: enable\n",
            "Antonyms: disable\n",
            "Hypernyms: change.v.01\n",
            "Hyponyms: endow.v.01,equip.v.02\n",
            "\n",
            "\n",
            "Word: machine\n",
            "Synonyms: machine\n",
            "Antonyms: \n",
            "Hypernyms: device.n.01\n",
            "Hyponyms: assembly.n.01,bagger.n.02,calculator.n.02,calender.n.01,cash_machine.n.01,comber.n.03,computer.n.01,concrete_mixer.n.01,corker.n.02,cotton_gin.n.01,decoder.n.02,farm_machine.n.01,franking_machine.n.01,hop-picker.n.01,machine_tool.n.01,machinery.n.01,milking_machine.n.01,motor.n.01,pavior.n.01,perpetual_motion_machine.n.01,pile_driver.n.01,power_shovel.n.01,power_tool.n.01,press.n.03,press.n.07,printer.n.03,record_player.n.01,riveting_machine.n.01,self-feeder.n.01,simulator.n.01,slicer.n.02,slot_machine.n.01,snow_thrower.n.01,sorter.n.02,stamp.n.07,staple_gun.n.01,stapler.n.01,textile_machine.n.01,time_machine.n.01,trimmer.n.02,workhorse.n.01,zamboni.n.01\n",
            "\n",
            "\n",
            "Word: understand\n",
            "Synonyms: understand\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: catch.v.18,follow.v.23,grok.v.01,interpret.v.01,make_out.v.03,penetrate.v.02,read.v.10,sense.v.04,solve.v.01,touch.v.13,understand.v.03\n",
            "\n",
            "\n",
            "Word: interpret\n",
            "Synonyms: interpret,construe,see\n",
            "Antonyms: \n",
            "Hypernyms: understand.v.01\n",
            "Hyponyms: allegorize.v.01,educe.v.01,literalize.v.01,misconstrue.v.01,mythicize.v.01,read.v.01,read.v.04,read_between_the_lines.v.01,reinterpret.v.02,spiritualize.v.01,take.v.06\n",
            "\n",
            "\n",
            "Word: generate\n",
            "Synonyms: generate,bring_forth\n",
            "Antonyms: \n",
            "Hypernyms: make.v.03\n",
            "Hyponyms: come_up.v.01,develop.v.13,induce.v.01,release.v.09\n",
            "\n",
            "\n",
            "Word: in\n",
            "Synonyms: inch,in\n",
            "Antonyms: \n",
            "Hypernyms: linear_unit.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: way\n",
            "Synonyms: manner,mode,style,way,fashion\n",
            "Antonyms: \n",
            "Hypernyms: property.n.02\n",
            "Hyponyms: artistic_style.n.01,drape.n.02,fit.n.03,form.n.11,life_style.n.01,response.n.07,setup.n.02,touch.n.04,wise.n.01\n",
            "\n",
            "\n",
            "Word: both\n",
            "Synonyms: both\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: meaningful\n",
            "Synonyms: meaningful\n",
            "Antonyms: meaningless\n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: useful\n",
            "Synonyms: useful,utile\n",
            "Antonyms: useless\n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: application\n",
            "Synonyms: application,practical_application\n",
            "Antonyms: \n",
            "Hypernyms: use.n.01\n",
            "Hyponyms: misapplication.n.01,technology.n.01\n",
            "\n",
            "\n",
            "Word: are\n",
            "Synonyms: are,ar\n",
            "Antonyms: \n",
            "Hypernyms: area_unit.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: widespread\n",
            "Synonyms: widespread\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: including\n",
            "Synonyms: include\n",
            "Antonyms: exclude\n",
            "Hypernyms: \n",
            "Hyponyms: embrace.v.01,hold.v.11,incorporate.v.02,inhere_in.v.01,involve.v.05,subsume.v.01\n",
            "\n",
            "\n",
            "Word: task\n",
            "Synonyms: undertaking,project,task,labor\n",
            "Antonyms: \n",
            "Hypernyms: work.n.01\n",
            "Hyponyms: adventure.n.01,assignment.n.05,baby.n.07,cinch.n.01,enterprise.n.01,labor_of_love.n.01,marathon.n.01,no-brainer.n.01,proposition.n.05,tall_order.n.01,venture.n.01\n",
            "\n",
            "\n",
            "Word: like\n",
            "Synonyms: like,the_like,the_likes_of\n",
            "Antonyms: \n",
            "Hypernyms: kind.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: text\n",
            "Synonyms: text,textual_matter\n",
            "Antonyms: \n",
            "Hypernyms: matter.n.06\n",
            "Hyponyms: column.n.08,cookie.n.03,copy.n.03,draft.n.05,electronic_text.n.01,installment.n.03,letter.n.01,line.n.05,lipogram.n.01,lyric.n.01,stanza.n.01\n",
            "\n",
            "\n",
            "Word: classification\n",
            "Synonyms: categorization,categorisation,classification,compartmentalization,compartmentalisation,assortment\n",
            "Antonyms: \n",
            "Hypernyms: grouping.n.02\n",
            "Hyponyms: indexing.n.01,reclassification.n.01,relegation.n.02,stratification.n.01,taxonomy.n.03,typology.n.01\n",
            "\n",
            "\n",
            "Word: sentiment\n",
            "Synonyms: sentiment\n",
            "Antonyms: \n",
            "Hypernyms: feeling.n.01\n",
            "Hyponyms: razbliuto.n.01,sentimentality.n.02\n",
            "\n",
            "\n",
            "Word: analysis\n",
            "Synonyms: analysis\n",
            "Antonyms: \n",
            "Hypernyms: investigation.n.02\n",
            "Hyponyms: anatomy.n.03,case_study.n.02,chemical_analysis.n.01,cost_analysis.n.01,dissection.n.03,fundamental_analysis.n.01,technical_analysis.n.01\n",
            "\n",
            "\n",
            "Word: translation\n",
            "Synonyms: translation,interlingual_rendition,rendering,version\n",
            "Antonyms: \n",
            "Hypernyms: written_record.n.01\n",
            "Hyponyms: mistranslation.n.01,pony.n.03,retroversion.n.02,subtitle.n.01,supertitle.n.01\n",
            "\n",
            "\n",
            "Word: advance\n",
            "Synonyms: progress,progression,advance\n",
            "Antonyms: \n",
            "Hypernyms: change_of_location.n.01\n",
            "Hyponyms: headway.n.02\n",
            "\n",
            "\n",
            "Word: deep\n",
            "Synonyms: deep\n",
            "Antonyms: \n",
            "Hypernyms: middle.n.04\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: learning\n",
            "Synonyms: learning,acquisition\n",
            "Antonyms: \n",
            "Hypernyms: basic_cognitive_process.n.01\n",
            "Hyponyms: conditioning.n.01,developmental_learning.n.01,digestion.n.03,education.n.03,imprinting.n.01,internalization.n.01,language_learning.n.01,memorization.n.01,study.n.02,transfer.n.05\n",
            "\n",
            "\n",
            "Word: particularly\n",
            "Synonyms: particularly,peculiarly,especially,specially\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: model\n",
            "Synonyms: model,theoretical_account,framework\n",
            "Antonyms: \n",
            "Hypernyms: hypothesis.n.02\n",
            "Hyponyms: copernican_system.n.01,m-theory.n.01,mean_sun.n.01,ptolemaic_system.n.01,simulation.n.02,stochastic_process.n.01,string_theory.n.01\n",
            "\n",
            "\n",
            "Word: transformer\n",
            "Synonyms: transformer\n",
            "Antonyms: \n",
            "Hypernyms: electrical_device.n.01\n",
            "Hyponyms: coil.n.03,step-down_transformer.n.01,step-up_transformer.n.01,tesla_coil.n.01,voltage_regulator.n.01\n",
            "\n",
            "\n",
            "Word: have\n",
            "Synonyms: rich_person,wealthy_person,have\n",
            "Antonyms: \n",
            "Hypernyms: person.n.01\n",
            "Hyponyms: affluent.n.01,billionaire.n.01,croesus.n.02,fat_cat.n.01,man_of_means.n.01,millionaire.n.01,millionairess.n.01,multi-billionaire.n.01,plutocrat.n.01\n",
            "\n",
            "\n",
            "Word: significantly\n",
            "Synonyms: significantly\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: improved\n",
            "Synonyms: better,improve,amend,ameliorate,meliorate\n",
            "Antonyms: worsen\n",
            "Hypernyms: change.v.01\n",
            "Hyponyms: advance.v.08,build.v.04,build_up.v.05,condition.v.04,educate.v.01,emend.v.01,enhance.v.02,enrich.v.01,fancify.v.01,fructify.v.02,help.v.02,help.v.08,iron_out.v.01,perfect.v.01,polish.v.02,purify.v.01,raise.v.25,reform.v.01,reform.v.05,regenerate.v.09,relieve.v.01,repair.v.01,turn_around.v.02,upgrade.v.02,upgrade.v.05\n",
            "\n",
            "\n",
            "Word: accuracy\n",
            "Synonyms: accuracy,truth\n",
            "Antonyms: inaccuracy\n",
            "Hypernyms: quality.n.01\n",
            "Hyponyms: exactness.n.01,fidelity.n.01\n",
            "\n",
            "\n",
            "Word: capability\n",
            "Synonyms: capability,capableness\n",
            "Antonyms: incapability,incapableness\n",
            "Hypernyms: ability.n.01\n",
            "Hyponyms: associability.n.01,capacity.n.01,defensibility.n.01,executability.n.01,military_capability.n.01,operating_capability.n.01,overkill.n.01\n",
            "\n",
            "\n",
            "Word: system\n",
            "Synonyms: system\n",
            "Antonyms: \n",
            "Hypernyms: instrumentality.n.03\n",
            "Hyponyms: audio_system.n.01,communication_system.n.01,computer_system.n.01,containment.n.02,control_system.n.01,data_system.n.01,drainage_system.n.01,exhaust.n.02,explosive_detection_system.n.01,explosive_trace_detection.n.01,guidance_system.n.01,hookup.n.02,inertial_guidance_system.n.01,lockage.n.02,maze.n.01,mechanical_system.n.01,navigational_system.n.01,network.n.04,network.n.05,propulsion_system.n.01,resonator.n.03,scaffolding.n.01,security_system.n.01,selsyn.n.01,shipboard_system.n.01,solar_thermal_system.n.01,sprinkler_system.n.01,synchromesh.n.01\n",
            "\n",
            "\n",
            "Word: making\n",
            "Synonyms: devising,fashioning,making\n",
            "Antonyms: \n",
            "Hypernyms: production.n.01\n",
            "Hyponyms: mapmaking.n.01,moviemaking.n.01\n",
            "\n",
            "\n",
            "Word: essential\n",
            "Synonyms: necessity,essential,requirement,requisite,necessary\n",
            "Antonyms: inessential\n",
            "Hypernyms: thing.n.12\n",
            "Hyponyms: desideratum.n.01,must.n.01,need.n.02\n",
            "\n",
            "\n",
            "Word: tool\n",
            "Synonyms: tool\n",
            "Antonyms: \n",
            "Hypernyms: implement.n.01\n",
            "Hyponyms: abrader.n.01,bender.n.01,clincher.n.03,comb.n.03,cutting_implement.n.01,drill.n.01,eolith.n.01,fork.n.04,gang.n.04,garden_tool.n.01,grapnel.n.01,hack.n.04,hand_tool.n.01,hoe.n.01,jack.n.10,jaws_of_life.n.01,neolith.n.01,paleolith.n.01,pestle.n.02,plow.n.01,power_tool.n.01,punch.n.03,rake.n.03,ram.n.04,rounder.n.02,saw_set.n.01,shaping_tool.n.01,strickle.n.03,stylus.n.02,tamp.n.01,tap.n.05,upset.n.04\n",
            "\n",
            "\n",
            "Word: ranging\n",
            "Synonyms: range,run\n",
            "Antonyms: \n",
            "Hypernyms: be.v.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: automated\n",
            "Synonyms: automatize,automatise,automate\n",
            "Antonyms: \n",
            "Hypernyms: change.v.01\n",
            "Hyponyms: semi-automatize.v.01\n",
            "\n",
            "\n",
            "Word: customer\n",
            "Synonyms: customer,client\n",
            "Antonyms: \n",
            "Hypernyms: consumer.n.01\n",
            "Hyponyms: buyer.n.01,guest.n.03,patron.n.01,policyholder.n.01,shopper.n.01,spender.n.03,subscriber.n.02,taker.n.01,warrantee.n.02,whoremaster.n.01\n",
            "\n",
            "\n",
            "Word: service\n",
            "Synonyms: service\n",
            "Antonyms: \n",
            "Hypernyms: work.n.01\n",
            "Hyponyms: consulting_service.n.01,facility.n.05,national_service.n.01,utility.n.03\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4o5qG5atHvpx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}